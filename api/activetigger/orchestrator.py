"""
Define the orchestrator and launch the instance that will span projects
Each project share a few elements:
- database manager
- queue
- users management
- messages management
"""

import asyncio
import os
import shutil
import time
import traceback
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import cast

import pandas as pd
import pyarrow.parquet as pq
import psutil
from jose import jwt

from activetigger import __version__
from activetigger.config import config
from activetigger.datamodels import (
    LMComputing,
    ProjectBaseModel,
    ServerStateModel,
    DatasetModel
)
from activetigger.db import DBException
from activetigger.db.manager import DatabaseManager
from activetigger.functions import get_dir_size, get_gpu_memory_info, slugify
from activetigger.messages import Messages
from activetigger.monitoring import Monitoring
from activetigger.project import Project
from activetigger.queue import Queue
from activetigger.users import Users


class Orchestrator:
    """
    Process to manage projects
    Use the config object to get parameters
    """

    starting_time: float
    db_name: str
    jwt_algorithm: str
    n_workers_cpu: int
    n_workers_gpu: int
    path: Path
    path_models: Path
    projects: dict[str, Project]
    db_manager: DatabaseManager
    queue: Queue
    users: Users
    messages: Messages
    max_projects: int
    project_creation_ongoing: dict[str, Project]
    monitoring: Monitoring

    def __init__(self) -> None:
        """
        Start the server
        """
        self.starting_time = time.time()

        self.max_projects = config.max_loaded_projects
        self.jwt_algorithm = config.jwt_algorithm
        self.n_workers_cpu = config.n_workers_cpu
        self.n_workers_gpu = config.n_workers_gpu

        # Define path
        self.path : Path = Path(config.data_path) / "projects"
        self.path_models : Path = Path(config.data_path) / "models"
        self.path_toy_datasets : Path = Path(self.path) / "toy-datasets"

        # create directories parent/static/models
        self.path.mkdir(parents=True, exist_ok=True)
        (self.path.joinpath("static")).mkdir(parents=True, exist_ok=True)
        self.path_models.mkdir(exist_ok=True)
        self.path_toy_datasets.mkdir(exist_ok=True)

        # attributes of the server
        self.db_manager = DatabaseManager()
        self.queue = Queue(
            nb_workers_cpu=self.n_workers_cpu,
            nb_workers_gpu=self.n_workers_gpu,
        )
        self.messages = Messages(self.db_manager)
        self.users = Users(self.db_manager, self.messages)
        self.monitoring = Monitoring(self.db_manager)

        # projects in memory
        self.projects = {}

        # projects in creation
        self.project_creation_ongoing = {}

        # update the projects asynchronously
        self._running = True
        self._update_task = asyncio.create_task(self._update(timeout=config.update_timeout))

        # create the demo project if not existing at startup
        try:
            if "demo" not in self.existing_projects():
                self.create_demo_project("demo", "demo")
        except Exception as e:
            print(f"Error while creating demo project: {e}")
        self.server_state = self.get_server_state()

    def __del__(self):
        """
        Close the server
        """
        print("Ending the server")
        if self._update_task:
            self._update_task.cancel()
        self._running = False
        del self.queue
        print("Server off")

    def reset(self):
        """
        Erase the waiting queue and projects in memory
        """
        self.queue.restart()
        self.projects = {}
        self.project_creation_ongoing = {}

    def starting_project_creation(self, project: ProjectBaseModel, username: str) -> str:
        """
        Start the project creation
        """
        project_slug = self.check_project_name(project.project_name)
        if project_slug in ["new"]:
            raise Exception("This project name is not valid - reserved word")
        self.project_creation_ongoing[project_slug] = Project(
            project_slug,
            self.queue,
            self.db_manager,
            path_models=self.path_models,
            users=self.users,
            messages=self.messages,
        )
        self.project_creation_ongoing[project_slug].start_project_creation(
            params=project,
            username=username,
            path=self.path,
        )
        return project_slug

    async def _update(self, timeout: int = 1, project_lifetime: int = 7200) -> None:
        """
        Update each project in memory every X seconds.
        - loaded project
        - project in creation
        Remove projects that are older than project_lifetime seconds.
        """
        try:
            while self._running:
                self.queue.clean_old_processes()
                timer = time.time()

                # loop on loaded projects
                to_del = []
                for p, project in self.projects.items():
                    try:
                        # if project existing since one day, remove it from memory
                        if (timer - project.starting_time) > project_lifetime:
                            to_del.append(p)
                            continue
                        project.update_processes()
                    except Exception as e:
                        print(f"Error while updating project {p}: {e}")
                        to_del.append(p)
                for p in to_del:
                    del self.projects[p]

                # loop on creating projects
                to_del = []
                for p, project in self.project_creation_ongoing.items():
                    try:
                        project.update_processes()
                        if project.status == "created":
                            to_del.append(p)
                        if project.status == "error":
                            self.clean_unfinished_project(project_slug=p)  # destroy everything
                            to_del.append(p)
                    except Exception as e:
                        print(f"Error while updating project {p}: {e}")
                        to_del.append(p)
                for p in to_del:
                    del self.project_creation_ongoing[p]

                # update the information on the state of the project
                self.server_state = self.get_server_state()
                await asyncio.sleep(timeout)
        except asyncio.CancelledError:
            print("Update task cancelled.")
        finally:
            print("Update task finished.")

    def log_action(
        self,
        user: str,
        action: str,
        project: str = "general",
        connect="not implemented",
    ) -> None:
        """
        Log action in the database
        """
        self.db_manager.logs_service.add_log(user, action, project, connect)

    def get_logs(self, project_slug: str, limit: int, partial: bool = True) -> pd.DataFrame:
        """
        Get logs for a user/project
        project_slug: project slug or "all"
        """
        logs = self.db_manager.logs_service.get_logs("all", project_slug, limit)
        df = pd.DataFrame(logs, columns=["id", "time", "user", "project", "action", "NA"])
        if partial:
            return df[~df["action"].str.contains("INFO ")]
        return df

    def get_server_state(self) -> ServerStateModel:
        """
        Build server state
        """
        # active projects in the orchestrator
        active_projects = {
            p: [
                {"unique_id": c.unique_id, "user": c.user, "kind": c.kind, "time": c.time}
                for c in self.projects[p].computing
            ]
            for p in self.projects
        }

        # running processes in the queue
        queue = {
            i.unique_id: i.model_dump()
            for i in self.queue.state()
            if i.state in ["pending", "running"]
        }

        # server state
        cpu = psutil.cpu_percent()
        cpu_count = psutil.cpu_count()
        memory_info = psutil.virtual_memory()
        disk_info = psutil.disk_usage("/")
        at_memory = get_dir_size(config.data_path + "/projects")

        return ServerStateModel(
            version=__version__,
            active_projects=active_projects,
            queue=queue,
            gpu=get_gpu_memory_info(),
            cpu={"proportion": cpu, "total": cpu_count},
            memory={
                "proportion": memory_info.percent,
                "total": memory_info.total / (1024**3),
                "available": memory_info.available / (1024**3),
            },
            disk={
                "activetigger": at_memory,
                "proportion": disk_info.percent,
                "total": disk_info.total / (1024**3),
            },
            mail_available=self.messages.mail_available,
            messages=self.messages.get_messages_system(),
        )

    def exists(self, project_name: str, include_toy_datasets: bool = False) -> bool:
        """
        Test if a project exists in the database
        with a sluggified form (to be able to use it in URL)
        """
        if include_toy_datasets:
            existing_projects : list[str] = self.existing_projects()
            toy_datasets : list[str] = [dataset.project_slug for dataset in self.get_toy_datasets()]
            return slugify(project_name) in existing_projects + toy_datasets
        else: 
            return slugify(project_name) in self.existing_projects()

    def check_project_name(self, project_name: str) -> str:
        """
        Check if a project name is valid
        """
        project_slug = slugify(project_name)
        if self.exists(project_slug):
            raise Exception("This project already exists")
        if project_slug == "":
            raise Exception("The project name is not valid - empty")
        return project_slug

    def create_access_token(self, data: dict, expires_min: int = 60) -> str:
        """
        Create access token
        """
        # create the token
        to_encode = data.copy()
        expire = datetime.now(timezone.utc) + timedelta(minutes=expires_min)
        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, config.secret_key, algorithm=self.jwt_algorithm)

        # add it in the database as active
        self.db_manager.projects_service.add_token(encoded_jwt, "active")

        return encoded_jwt

    def revoke_access_token(self, token) -> None:
        """
        Revoke existing access token
        """
        self.db_manager.projects_service.revoke_token(token)

    def decode_access_token(self, token: str) -> dict:
        """
        Decode access token
        """
        # get status
        try:
            status = self.db_manager.projects_service.get_token_status(token)
        except DBException as e:
            raise Exception from e

        if status != "active":
            raise Exception("Token is invalid")

        # decode payload
        payload = jwt.decode(token, config.secret_key, algorithms=[self.jwt_algorithm])
        return payload

    def manage_fifo_queue(self) -> None:
        """
        Manage the current projects in memory for an orchestrator
        """
        if len(self.projects) >= self.max_projects:
            old_element = sorted(
                [(p, self.projects[p].starting_time) for p in self.projects],
                key=lambda x: x[1],
            )[0]
            if (
                old_element[1] < time.time() - 600
            ):  # check if the project has a least ten minutes old to avoid destroying current projects
                del self.projects[old_element[0]]
                print(f"Delete project {old_element[0]} to gain memory")
            else:
                print("Too many projects in the current memory")
                raise Exception(
                    "There is too many projects currently loaded in this server. Please wait"
                )

    def start_project(self, project_slug: str) -> None:
        """
        Load project in server
        """
        if not self.exists(project_slug):
            raise Exception("This project does not exist")

        try:
            self.projects[project_slug] = Project(
                project_slug,
                self.queue,
                self.db_manager,
                path_models=self.path_models,
                users=self.users,
                messages=self.messages,
            )
        except Exception as e:
            raise Exception(
                f"Error while loading project {project_slug}: {e} - {traceback.format_exc()}"
            ) from e

    def stop_project(self, project_slug: str) -> None:
        """
        Stop a project
        """
        if project_slug not in self.projects:
            return None
        del self.projects[project_slug]

    def stop_process(self, process_id: str, username: str) -> None:
        """
        Stop a specific process
        """
        self.queue.kill(process_id)
        self.log_action(username, f"KILL PROCESS: {process_id}", "all")

    def stop_user_processes(
        self, username: str, project_slug: str | None = None, kind: str | list[str] | None = None
    ) -> None:
        """
        Stop all the processes of a user
        """

        # define the processes to kill
        if kind == "all":
            kind = ["train_bert", "predict_bert", "generation", "feature", "bertopic"]
        if kind == "bert":
            kind = ["train_bert", "predict_bert"]
        if kind is None:
            kind = "all"
        if isinstance(kind, str) and kind != "all":
            kind = [kind]

        # kill all the processes of the user
        if project_slug is None:
            processes = {p: self.projects[p].get_process(kind, username) for p in self.projects}
            for project in processes:
                for process in processes[project]:
                    self.queue.kill(process.unique_id)
                    if process.kind == "train_bert":
                        process = cast(LMComputing, process)
                        self.db_manager.language_models_service.delete_model(
                            project, process.model_name
                        )
        # kill all the processes of the user for a specific project
        else:
            if project_slug not in self.projects:
                raise Exception("This project is not loaded in memory")
            processes_project = self.projects[project_slug].get_process(kind, username)
            for process in processes_project:
                self.queue.kill(process.unique_id)
                if process.kind == "train_bert":
                    process = cast(LMComputing, process)
                    self.db_manager.language_models_service.delete_model(
                        project_slug, process.model_name
                    )

    def existing_projects(self) -> list:
        """
        Get existing projects
        """
        return self.db_manager.projects_service.existing_projects()

    def delete_project(self, project_slug: str) -> None:
        """
        Delete a project
        """

        # test if the project exists
        if not self.exists(project_slug):
            raise Exception("This project does not exist")

        # load the project
        if project_slug in self.projects:
            project = self.projects[project_slug]
        else:
            self.start_project(project_slug)
            project = self.projects[project_slug]

        # delete the project
        try:
            project.delete()
        except Exception as e:
            raise Exception from e

        # clean current memory
        if project_slug in self.projects:
            del self.projects[project_slug]

    def clean_unfinished_project(
        self, project_slug: str | None = None, project_name: str | None = None
    ) -> None:
        """
        Clean a project that is not loadable
        Careful : this will delete all the data of the project
        """

        if project_slug is not None:
            project_slug_verif = project_slug
        elif project_name is not None:
            project_slug_verif = slugify(project_name)
        else:
            raise Exception("No project specified")

        # remove from database
        self.db_manager.projects_service.delete_project(project_slug_verif)

        # remove from the server
        if project_slug_verif and project_slug_verif != "":
            shutil.rmtree(self.path.joinpath(project_slug_verif), ignore_errors=True)

            ## remove static files
            if Path(f"{config.data_path}/projects/static/{project_slug_verif}").exists():
                shutil.rmtree(f"{config.data_path}/projects/static/{project_slug_verif}")

    def create_demo_project(self, project_name: str, username: str) -> None:
        """
        Create a demo project for a specific user
        """
        # TODO : put those elements in the config file
        path_data = Path("../frontend/public/dataset_test.csv")
        col_id = "id"
        col_text = "sentence"
        col_label = "label_agg"

        if not path_data.exists():
            raise Exception("The demo dataset is not available")

        # create name of the project and the directory
        project_name = project_name
        project_slug = slugify(project_name)
        project_path = self.path.joinpath(project_slug)
        os.makedirs(project_path, exist_ok=True)

        # create and save a toy dataset
        df = pd.read_csv(path_data)
        df.to_csv(project_path.joinpath("dataset.csv"), index=False)

        # parameters of the project and creation
        project = ProjectBaseModel(
            project_name=project_name,
            language="en",
            filename="dataset.csv",
            col_id=col_id,
            cols_text=[col_text],
            cols_label=[col_label],
            n_train=1000,
            n_test=500,
        )
        self.starting_project_creation(project, username)

    def available_storage(self, username: str) -> bool:
        """
        Check if the user storage is not exceeded
        """
        limit = self.users.get_storage_limit(username)
        if self.users.get_storage(username) > limit * 1000:
            return False
        return True
    
    def get_toy_datasets(self) -> list[DatasetModel]:
        """
        Get the name of available toy datasets
        """
        toy_datasets = []
        for file in os.listdir(self.path_toy_datasets):
            if file.endswith(".parquet"):
                toy_dataset_name = file.removesuffix(".parquet")
                pq_file = pq.ParquetFile(self.path_toy_datasets.joinpath(file))
                toy_datasets += [DatasetModel(
                    project_slug = toy_dataset_name,
                    columns = [col.name for col in list(pq_file.schema)],
                    n_rows = pq_file.metadata.num_rows
                )]
        return toy_datasets


# launch the instance
orchestrator = Orchestrator()
